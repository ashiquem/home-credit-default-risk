{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import ftextraction\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "import lightgbm as lgbm\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = ftextraction.Extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "start = time.time()\n",
    "app_train = pd.read_csv('data/application_train.csv')\n",
    "app_test = pd.read_csv('data/application_test.csv')\n",
    "buro = pd.read_csv('data/bureau.csv')\n",
    "bb = pd.read_csv('data/bureau_balance.csv')\n",
    "ccb = pd.read_csv('data/credit_card_balance.csv')\n",
    "ipay = pd.read_csv('data/installments_payments.csv')\n",
    "pos = pd.read_csv('data/POS_CASH_balance.csv')\n",
    "pa = pd.read_csv('data/previous_application.csv')\n",
    "end = time.time()\n",
    "print('Datasets loaded in: {:.2f} minutes'.format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process datasets\n",
    "# start = time.time()\n",
    "# data = fe.process_datasets(app_train,app_test,buro,bb,pa,ipay,ccb,pos,fe=False,path='processed/alldata.csv')\n",
    "# data_fe = fe.process_datasets(app_train,app_test,buro,bb,pa,ipay,ccb,pos,path='processed/alldata_fe.csv')\n",
    "# end = time.time()\n",
    "# print('Datasets processed in: {:.2f} minutes'.format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed/alldata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_baseline(data):\n",
    "\n",
    "    #preprocessing data    \n",
    "    train = data.loc[data['TARGET'].notnull(),:].copy()\n",
    "    test = data.loc[data['TARGET'].isnull(),:].copy()\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "    labels = train['TARGET']\n",
    "\n",
    "    train.drop(columns=['TARGET','SK_ID_CURR'],inplace=True)\n",
    "    test.drop(columns=['TARGET','SK_ID_CURR'],inplace=True)\n",
    "    \n",
    "    train,test = train.align(test,join='inner',axis=1)\n",
    "    \n",
    "    # Impute training and testing data\n",
    "\n",
    "    imputer = Imputer(strategy='median')\n",
    "    imputer.fit(train)\n",
    "    train = imputer.transform(train)\n",
    "    test = imputer.transform(test)\n",
    "    \n",
    "   \n",
    "    features = list(train.columns)\n",
    "    fi = np.zeros(len(features))\n",
    "    \n",
    "    classifier = RandomForestClassifier()\n",
    "    # converting to numpy array \n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    scores = {}\n",
    "    \n",
    "    #splitting datasets\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(train, labels, test_size=0.33, random_state=42)\n",
    "    start = time.time()\n",
    "    classifier.fit(x_train,y_train)\n",
    "    #prediction on cv set\n",
    "    cv_preds = classifier.predict_proba(x_valid)[:,1]\n",
    "    #prediction on test set\n",
    "    test_pred = classifier.predict_proba(test)[:,1]\n",
    "    #prediction on training set\n",
    "    train_pred = classifier.predict_proba(x_train)[:,1]\n",
    "    end = time.time()\n",
    "    print('Training done in {:.2f} minutes'.format((end-start)/60))\n",
    "    #recording scores\n",
    "    scores['training score'] = [roc_auc_score(y_train,train_pred)]\n",
    "    scores['validation score'] = [roc_auc_score(y_valid,cv_preds)]\n",
    "    print('Training score: {:.4f} | CV Score: {:.4f}'\\\n",
    "          .format(roc_auc_score(y_train,train_pred),roc_auc_score(y_valid,cv_preds)))\n",
    "    #store feature importance\n",
    "    fi = classifier.feature_importances_\n",
    "    \n",
    "    del x_train, x_valid, y_train, y_valid\n",
    "    gc.collect()\n",
    "\n",
    "    scores = pd.DataFrame.from_dict(scores)\n",
    "    \n",
    "    #feature importance\n",
    "    f_importance = pd.DataFrame(columns=['feature','importance'])\n",
    "    f_importance['Feature'] = features\n",
    "    f_importance['importance'] = fi\n",
    "    \n",
    "    return scores,test_pred,f_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling with all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores,rf_test_pred,rf_f_importance = rf_baseline(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling with engineered features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores_fe,rf_test_pred_fe,rf_f_importance_fe = rf_baseline(data_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Improved Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbmV0(data,folds,iterations):\n",
    "       \n",
    "    #preprocessing data    \n",
    "    train = data.loc[data['TARGET'].notnull(),:].copy()\n",
    "    test = data.loc[data['TARGET'].isnull(),:].copy()\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "    # save test IDs for final submission dataframe\n",
    "    test_IDs = test['SK_ID_CURR']\n",
    "    # save target labels\n",
    "    labels = train['TARGET']\n",
    "    # drop ID columns\n",
    "    train = train.drop(columns=['SK_ID_CURR','TARGET'])\n",
    "    test = test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "\n",
    "    # drop features with no importance\n",
    "    train.drop(columns=exclude,inplace=True)\n",
    "    test.drop(columns=exclude,inplace=True)\n",
    "\n",
    "    # aligining dataframes\n",
    "    train,test = train.align(test,join='inner',axis=1)\n",
    "\n",
    "    # for storing feature importances\n",
    "    features = list(train.columns)\n",
    "    ft_importances = np.zeros(len(features))\n",
    "\n",
    "    # converting to numpy array for lgbm consumptions\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "\n",
    "    #DATA STRUCTURES TO STORE PREDICTIONS AND METRICS\n",
    "\n",
    "    #store cv predictions\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    #store predictions on test dataset\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    #store predictions on train dataset\n",
    "    train_preds = np.zeros(train.shape[0])\n",
    "    #store scores\n",
    "    scores = {}\n",
    "\n",
    "    #SPLITTING AND TRAINING \n",
    "    kfold = StratifiedKFold(n_splits=folds,shuffle=True,random_state=40)\n",
    "    fold = 1\n",
    "    start = time.time()\n",
    "    for train_i,valid_i in kfold.split(train,labels):\n",
    "        xtrain,ytrain = train[train_i],labels[train_i]\n",
    "        xvalid,yvalid = train[valid_i],labels[valid_i]\n",
    "        \n",
    "        # creating the classifier \n",
    "        clf = lgbm.LGBMClassifier()\n",
    "\n",
    "        # fitting on the training set, early stopping using validation set\n",
    "        clf.fit(xtrain,ytrain,verbose= 200)\n",
    "\n",
    "        # storing out of fold predictions:\n",
    "        oof_predictions[valid_i] = clf.predict_proba(xvalid)[:, 1]\n",
    "\n",
    "        # storing test set predictions:\n",
    "        test_preds += clf.predict_proba(test)[:, 1] /kfold.n_splits\n",
    "\n",
    "        #stortin training set predictions\n",
    "        train_preds[train_i] = clf.predict_proba(xtrain)[:, 1]\n",
    "\n",
    "        # storing feature importances            \n",
    "        ft_importances += clf.feature_importances_ /kfold.n_splits\n",
    "        print('Fold %d done.'%fold)\n",
    "        fold += fold\n",
    "        # freeing up memory\n",
    "        del xtrain,ytrain,xvalid,yvalid,clf\n",
    "        gc.collect()\n",
    "        \n",
    "    end = time.time()    \n",
    "    print('Training done in {:.2f} minutes'.format((end-start)/60))    \n",
    "    #SCORES\n",
    "\n",
    "    feature_importances = pd.DataFrame({'features':features,'importance':ft_importances})\n",
    "    \n",
    "    training_score = roc_auc_score(labels,train_preds)\n",
    "    cv = roc_auc_score(labels,oof_predictions)\n",
    "    scores['training score'] = [training_score]\n",
    "    scores['cv score'] = [cv]\n",
    "    scores = pd.DataFrame.from_dict(scores)\n",
    "    print('Overall CV Score: %.4f' %cv)\n",
    "    # submission dataframe:\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_IDs, 'TARGET': test_preds})\n",
    "\n",
    "    return submission, scores, feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_lgbmV0, scores_lgbmV0, fi_lgbm_V0 = lgbmV0(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_lgbmV0_fe, scores_lgbmV0_fe, fi_lgbm_V0_fe = lgbmV0(data_fe,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
