{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ftextraction\n",
    "import pandas as pd\n",
    "import os\n",
    "%config IPCompleter.greedy=True\n",
    "import gc\n",
    "gc.enable()\n",
    "import numpy as np\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['application_test.csv',\n",
       " 'application_train.csv',\n",
       " 'bureau.csv',\n",
       " 'bureau_balance.csv',\n",
       " 'credit_card_balance.csv',\n",
       " 'HomeCredit_columns_description.csv',\n",
       " 'installments_payments.csv',\n",
       " 'POS_CASH_balance.csv',\n",
       " 'previous_application.csv',\n",
       " 'sample_submission.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ftextraction.Extractor()\n",
    "def df_info(df):\n",
    "    print(f'Data frame shape: {df.shape}')\n",
    "    print('Memory usage: %.2f MB' %(df.memory_usage().sum()/(1024*1024)))\n",
    "    \n",
    "def missing_values(df):\n",
    "    missing = df.isnull().sum().sort_values(ascending=False)\n",
    "    count = missing[missing != 0]\n",
    "    prcnt = (count/len(df)*100).round(1)\n",
    "    return pd.concat([count,prcnt],axis=1,keys=['Count','Percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bureau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "buro = pd.read_csv('data/bureau.csv')\n",
    "buro_num = extractor.numerical_feature_stats(buro,'SK_ID_CURR','buro',exclude=['SK_ID_BUREAU'])\n",
    "buro_num.to_csv('processed/bureau_num.csv')\n",
    "buro_cat = extractor.categorical_stats(buro,'SK_ID_CURR','buro',exclude=['SK_ID_BUREAU'])\n",
    "buro_cat.to_csv('processed/bureau_cat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bureau Balance Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "buro_b = pd.read_csv('data/bureau_balance.csv')\n",
    "bb_num = extractor.numerical_feature_stats(buro_b,'SK_ID_BUREAU','bb')\n",
    "bb_cat = extractor.categorical_stats(buro_b,'SK_ID_BUREAU','bb')\n",
    "bb = pd.merge(bb_num,bb_cat,on='SK_ID_BUREAU',how='outer')\n",
    "bb_client = pd.merge(buro[['SK_ID_CURR','SK_ID_BUREAU']],bb,on='SK_ID_BUREAU',how='left')\n",
    "bb_client = extractor.numerical_feature_stats(bb_client,'SK_ID_CURR','client',exclude=['SK_ID_BUREAU'])\n",
    "bb_client.to_csv('processed/bureau_balance_by_client.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Applications Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_apps = pd.read_csv('data/previous_application.csv')\n",
    "p_apps_numerical = extractor.numerical_feature_stats(p_apps,'SK_ID_CURR','prv_app',exclude=['SK_ID_PREV'])\n",
    "p_app_cat = extractor.categorical_stats(p_apps,'SK_ID_CURR','prv_app',exclude=['SK_ID_PREV'])\n",
    "p_app_cat.to_csv('processed/p_apps_cat.csv')\n",
    "p_apps_numerical.to_csv('processed/p_apps_num.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installments Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_pay = pd.read_csv('data/installments_payments.csv')\n",
    "ins_pay_loan = extractor.numerical_feature_stats(ins_pay,'SK_ID_PREV','ins_pay',exclude=['SK_ID_CURR'])\n",
    "ins_pay_loan_client = pd.merge(p_apps[['SK_ID_PREV','SK_ID_CURR']],ins_pay_loan,how='left',on='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTALLMENTS DATA BY CLIENT\n",
    "ins_pay_loan_client = extractor.\\\n",
    "numerical_feature_stats(ins_pay_loan_client,'SK_ID_CURR','client',exclude=['SK_ID_PREV'])\n",
    "ins_pay_loan_client.to_csv('ins_pay_loan_client.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit Card Balance data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_balance = pd.read_csv('data/credit_card_balance.csv')\n",
    "cc_balance_num = extractor.numerical_feature_stats(cc_balance,'SK_ID_PREV','ccb',exclude=['SK_ID_CURR'])\n",
    "cc_balance_cat = extractor.categorical_stats(cc_balance,'SK_ID_PREV','ccb',exclude=['SK_ID_CURR'])\n",
    "cc_balance_pa = pd.merge(cc_balance_num,cc_balance_cat,on='SK_ID_PREV',how='outer')\n",
    "#CREDIT CARD BALANCE DATA BY CLIENT:\n",
    "cc_b_client = pd.merge(p_apps[['SK_ID_PREV','SK_ID_CURR']],cc_balance_pa,on='SK_ID_PREV',how='left')\n",
    "cc_b_client = extractor.numerical_feature_stats(cc_b_client,'SK_ID_CURR','client',exclude=['SK_ID_PREV'])\n",
    "cc_b_client.to_csv('cc_b_client.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Cash Balance Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cb = pd.read_csv('data/POS_CASH_balance.csv')\n",
    "pos_cb_num = extractor.numerical_feature_stats(pos_cb,'SK_ID_PREV','poscb',exclude=['SK_ID_CURR'])\n",
    "pos_cb_cat = extractor.categorical_stats(pos_cb,'SK_ID_PREV','poscb',exclude=['SK_ID_CURR'])\n",
    "pos_cb_loan = pd.merge(pos_cb_num,pos_cb_cat,on='SK_ID_PREV',how='outer')\n",
    "pos_cb_client = pd.merge(p_apps[['SK_ID_PREV','SK_ID_CURR']],pos_cb_loan,on='SK_ID_PREV',how='left')\n",
    "pos_cb_client = extractor.numerical_feature_stats(pos_cb_client,'SK_ID_CURR','client',exclude=['SK_ID_PREV'])\n",
    "pos_cb_client.to_csv('pos_cb_client.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_pay_loan_client = pd.read_csv('processed/ins_pay_loan_client.csv')\n",
    "cc_b_client = pd.read_csv('processed/cc_b_client.csv')\n",
    "pos_cb_client = pd.read_csv('processed/pos_cb_client.csv')\n",
    "p_apps_num = pd.read_csv('processed/p_apps_num.csv')\n",
    "p_apps_cat = pd.read_csv('processed/p_apps_cat.csv')\n",
    "bureau_balance_by_client = pd.read_csv('processed/bureau_balance_by_client.csv')\n",
    "bureau_num = pd.read_csv('processed/bureau_num.csv')\n",
    "bureau_cat = pd.read_csv('processed/bureau_cat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installments Database...\n",
      "\n",
      "Data frame shape: (338857, 152)\n",
      "Memory usage: 392.96 MB\n",
      "Credit Card Balance Database...\n",
      "\n",
      "Data frame shape: (338857, 572)\n",
      "Memory usage: 1478.78 MB\n",
      "POS Cash Balance...\n",
      "\n",
      "Data frame shape: (338857, 217)\n",
      "Memory usage: 561.00 MB\n",
      "Previous Applications Numerical...\n",
      "\n",
      "Data frame shape: (338857, 97)\n",
      "Memory usage: 250.77 MB\n",
      "Previous Applications Categorical...\n",
      "\n",
      "Data frame shape: (338857, 288)\n",
      "Memory usage: 744.56 MB\n",
      "Bureau Balance Database...\n",
      "\n",
      "Data frame shape: (305811, 107)\n",
      "Memory usage: 249.65 MB\n",
      "Bureau Numerical.....\n",
      "\n",
      "Data frame shape: (305811, 62)\n",
      "Memory usage: 144.66 MB\n",
      "Bureau Categorical....\n",
      "\n",
      "Data frame shape: (305811, 48)\n",
      "Memory usage: 111.99 MB\n"
     ]
    }
   ],
   "source": [
    "print('Installments Database...\\n')\n",
    "df_info(ins_pay_loan_client)\n",
    "print('Credit Card Balance Database...\\n')\n",
    "df_info(cc_b_client)\n",
    "print('POS Cash Balance...\\n')\n",
    "df_info(pos_cb_client)\n",
    "print('Previous Applications Numerical...\\n')\n",
    "df_info(p_apps_num)\n",
    "print('Previous Applications Categorical...\\n')\n",
    "df_info(p_apps_cat)\n",
    "print('Bureau Balance Database...\\n')\n",
    "df_info(bureau_balance_by_client)\n",
    "print('Bureau Numerical.....\\n')\n",
    "df_info(bureau_num)\n",
    "print('Bureau Categorical....\\n')\n",
    "df_info(bureau_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DROPPING COLUMNS WITH HIGH MISSING VALUES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_high_missing(df):\n",
    "    missing = missing_values(df)\n",
    "    cols = list(missing.loc[missing['Percent']>80].index)\n",
    "    df = df.drop(columns=cols)\n",
    "    print('Dropped %d columns'%len(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [ins_pay_loan_client,cc_b_client,pos_cb_client,p_apps_num,p_apps_cat,bureau_balance_by_client,bureau_num,bureau_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns\n",
      "Dropped 63 columns\n",
      "Dropped 0 columns\n",
      "Dropped 6 columns\n",
      "Dropped 0 columns\n",
      "Dropped 0 columns\n",
      "Dropped 0 columns\n",
      "Dropped 0 columns\n"
     ]
    }
   ],
   "source": [
    "#DROPPING COLUMNS\n",
    "for dataset in all_data:\n",
    "    drop_high_missing(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING MAIN TRAINING AND TESTING DATASETS:\n",
    "app_train = pd.read_csv('data/application_train.csv')\n",
    "app_test = pd.read_csv('data/application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOINING INSTALLMENTS PAYMENTS DATA:\n",
    "app_train = pd.merge(app_train,ins_pay_loan_client,on='SK_ID_CURR',how='left')\n",
    "#JOINING CREDIT CARD BALANCE DATA:\n",
    "app_train = pd.merge(app_train,cc_b_client,on='SK_ID_CURR',how='left')\n",
    "#JOINING POS BALANCE DATA:\n",
    "app_train = pd.merge(app_train,pos_cb_client,on='SK_ID_CURR',how='left')\n",
    "#JOINING PREVIOUS APPLICATIONS CATEGORICAL\n",
    "app_train = pd.merge(app_train,p_apps_cat,on='SK_ID_CURR',how='left')\n",
    "#JOINING PREVIOUS APPLICATIONS NUMERICAL\n",
    "app_train = pd.merge(app_train,p_apps_num,on='SK_ID_CURR',how='left')\n",
    "#JOINING BUREAU NUMERICAL DATA:\n",
    "app_train = pd.merge(app_train,bureau_num,on='SK_ID_CURR',how='left')\n",
    "#JOINING BUREAU CATEGORICAL DATA:\n",
    "app_train = pd.merge(app_train,bureau_cat,on='SK_ID_CURR',how='left')\n",
    "#JOINING BUREAU BALANCE DATA:\n",
    "app_train = pd.merge(app_train,bureau_balance_by_client,on='SK_ID_CURR',how='left')\n",
    "\n",
    "#SAVING DATABASE:\n",
    "app_train.to_csv('app_train_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOINING INSTALLMENTS PAYMENTS DATA:\n",
    "app_test = pd.merge(app_test,ins_pay_loan_client,on='SK_ID_CURR',how='left')\n",
    "#JOINING CREDIT CARD BALANCE DATA:\n",
    "app_test = pd.merge(app_test,cc_b_client,on='SK_ID_CURR',how='left')\n",
    "#JOINING POS BALANCE DATA:\n",
    "app_test = pd.merge(app_test,pos_cb_client,on='SK_ID_CURR',how='left')\n",
    "#JOINING PREVIOUS APPLICATIONS CATEGORICAL\n",
    "app_test = pd.merge(app_test,p_apps_cat,on='SK_ID_CURR',how='left')\n",
    "#JOINING PREVIOUS APPLICATIONS NUMERICAL\n",
    "app_test = pd.merge(app_test,p_apps_num,on='SK_ID_CURR',how='left')\n",
    "#JOINING BUREAU NUMERICAL DATA:\n",
    "app_test = pd.merge(app_test,bureau_num,on='SK_ID_CURR',how='left')\n",
    "#JOINING BUREAU CATEGORICAL DATA:\n",
    "app_test = pd.merge(app_test,bureau_cat,on='SK_ID_CURR',how='left')\n",
    "#JOINING BUREAU BALANCE DATA:\n",
    "app_test = pd.merge(app_test,bureau_balance_by_client,on='SK_ID_CURR',how='left')\n",
    "#SAVING DATABASE\n",
    "app_test = app_test.to_csv('app_test_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligning training and testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test = pd.read_csv('app_test_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = app_train['TARGET']\n",
    "\n",
    "train, test = app_train.align(app_test,join='inner',axis=1)\n",
    "\n",
    "train['TARGET'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (307511, 1657)\n",
      "Testing shape:  (48744, 1656)\n"
     ]
    }
   ],
   "source": [
    "print('Training shape: ',train.shape)\n",
    "print('Testing shape: ',test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (307511, 1779)\n",
      "Testing shape:  (48744, 1776)\n"
     ]
    }
   ],
   "source": [
    "#DROP COLUMNS\n",
    "train = train.drop(columns=['SK_ID_CURR','TARGET'])\n",
    "test = test.drop(columns=['SK_ID_CURR'])\n",
    "#ONE HOT ENCODING DATASETS:\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:(230633, 1779)\n",
      "Validation set size:(76878, 1779)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train,labels,test_size=0.25, shuffle=True,random_state=42)\n",
    "\n",
    "print('Training set size:{}'.format(x_train.shape))\n",
    "print('Validation set size:{}'.format(x_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "#CREATING LGBM DATASETS:\n",
    "train_set = lgb.Dataset(x_train,label=y_train)\n",
    "valid_set = lgb.Dataset(x_valid,label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters:\n",
    "\n",
    "params = {'boosting_type': 'gbdt', 'max_depth' : 10,\n",
    "          'objective': 'binary','nthread': 5,'num_leaves': 64,\n",
    "          'learning_rate': 0.05,'max_bin': 512,'subsample_for_bin': 200,\n",
    "          'subsample': 1,'subsample_freq': 1,'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,'reg_lambda': 10,'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,'num_class' : 1,\n",
    "          'metric' : 'auc'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds.\n",
      "[10]\tvalid_0's auc: 0.743034\n",
      "[20]\tvalid_0's auc: 0.751258\n",
      "[30]\tvalid_0's auc: 0.755675\n",
      "[40]\tvalid_0's auc: 0.759519\n",
      "[50]\tvalid_0's auc: 0.763693\n",
      "[60]\tvalid_0's auc: 0.767265\n",
      "[70]\tvalid_0's auc: 0.770573\n",
      "[80]\tvalid_0's auc: 0.7729\n",
      "[90]\tvalid_0's auc: 0.774804\n",
      "[100]\tvalid_0's auc: 0.776323\n",
      "[110]\tvalid_0's auc: 0.777371\n",
      "[120]\tvalid_0's auc: 0.778304\n",
      "[130]\tvalid_0's auc: 0.779288\n",
      "[140]\tvalid_0's auc: 0.779977\n",
      "[150]\tvalid_0's auc: 0.780646\n",
      "[160]\tvalid_0's auc: 0.781373\n",
      "[170]\tvalid_0's auc: 0.781869\n",
      "[180]\tvalid_0's auc: 0.78231\n",
      "[190]\tvalid_0's auc: 0.782761\n",
      "[200]\tvalid_0's auc: 0.78302\n",
      "[210]\tvalid_0's auc: 0.783347\n",
      "[220]\tvalid_0's auc: 0.783606\n",
      "[230]\tvalid_0's auc: 0.783812\n",
      "[240]\tvalid_0's auc: 0.784018\n",
      "[250]\tvalid_0's auc: 0.784195\n",
      "[260]\tvalid_0's auc: 0.784502\n",
      "[270]\tvalid_0's auc: 0.784653\n",
      "[280]\tvalid_0's auc: 0.784831\n",
      "[290]\tvalid_0's auc: 0.784874\n",
      "[300]\tvalid_0's auc: 0.784965\n",
      "[310]\tvalid_0's auc: 0.785188\n",
      "[320]\tvalid_0's auc: 0.785098\n",
      "[330]\tvalid_0's auc: 0.785142\n",
      "[340]\tvalid_0's auc: 0.785302\n",
      "[350]\tvalid_0's auc: 0.785363\n",
      "[360]\tvalid_0's auc: 0.785299\n",
      "[370]\tvalid_0's auc: 0.785263\n",
      "[380]\tvalid_0's auc: 0.785264\n",
      "Early stopping, best iteration is:\n",
      "[348]\tvalid_0's auc: 0.785409\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb.train(params,\n",
    "                 train_set,\n",
    "                 2500,\n",
    "                 valid_sets=valid_set,\n",
    "                 early_stopping_rounds= 40,\n",
    "                 verbose_eval= 10\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lightgbm.basic.Dataset"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lgbm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission.TARGET = predictions\n",
    "submission.to_csv('all_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission scores **0.771** on the PLB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_lgbm(train,test,folds):\n",
    "    \n",
    "    #PREPROCESSING DATA\n",
    "    \n",
    "    # save test IDs for final submission dataframe\n",
    "    test_IDs = test['SK_ID_CURR']\n",
    "    # save target labels\n",
    "    labels = train['TARGET']\n",
    "    # drop unnecessary columns\n",
    "    train = train.drop(columns=['SK_ID_CURR','TARGET'])\n",
    "    test = test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "    # encode categorical variables\n",
    "    train = pd.get_dummies(train)\n",
    "    test = pd.get_dummies(test)\n",
    "    \n",
    "    # aligining dataframes\n",
    "    train,test = train.align(test,join='inner',axis=1)\n",
    "    \n",
    "    # converting to numpy array for lgbm consumptions\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    #DATA STRUCTURES TO STORE PREDICTIONS AND METRICS\n",
    "    \n",
    "    #store cv predictions\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    #store predictions on test dataset\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    #store ROC score for cv predictions\n",
    "    cv_roc_train = []\n",
    "    cv_roc_valid = []\n",
    "    cv_score = pd.DataFrame()\n",
    "    \n",
    "    #SPLITTING AND TRAINING \n",
    "    kfold = KFold(n_splits=folds,shuffle=True,random_state=40)\n",
    "    \n",
    "    for train_i,valid_i in kfold.split(train):\n",
    "        xtrain,ytrain = train[train_i],labels[train_i]\n",
    "        xvalid,yvalid = train[valid_i],labels[valid_i]\n",
    "        \n",
    "        # creating the classifier \n",
    "        clf = lgbm.LGBMClassifier(n_estimators=10000, objective = 'binary', \n",
    "                                   class_weight = 'balanced', learning_rate = 0.05, \n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, \n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n",
    "        \n",
    "        # fitting on the training set, early stopping using validation set\n",
    "        clf.fit(xtrain,ytrain,eval_set=[(xtrain, ytrain), (xvalid, yvalid)],eval_metric ='auc',\n",
    "               verbose= 200, early_stopping_rounds= 100,eval_names = ['train','valid'])\n",
    "        \n",
    "        # recording best iteration\n",
    "        best_iter = clf.best_iteration_\n",
    "        \n",
    "        # storing out of fold predictions:\n",
    "        oof_predictions[valid_i] = clf.predict_proba(xvalid,num_iteration=best_iter)[:, 1]\n",
    "        \n",
    "        # storing training and validation scores\n",
    "        cv_roc_train.append(clf.best_score_['train'])\n",
    "        cv_roc_valid.append(clf.best_score_['valid'])\n",
    "\n",
    "        # storing test set predictions:\n",
    "        test_preds += (clf.predict_proba(test,num_iteration=best_iter)[:, 1]) /kfold.n_splits\n",
    "        \n",
    "        # freeing up memory\n",
    "        del xtrain,ytrain,xvalid,yvalid,clf\n",
    "        gc.collect()\n",
    "        \n",
    "    #SCORES\n",
    "    \n",
    "    cv_score['Fold'] = np.arange(kfold.n_splits)\n",
    "    cv_score['Training Score'] = cv_roc_train\n",
    "    cv_score['Validation Score'] = cv_roc_valid\n",
    "    overall = roc_auc_score(labels,oof_predictions)\n",
    "    print('Overall CV Score: %.2f' %overall)\n",
    "    # submission dataframe:\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_IDs, 'TARGET': test_preds})\n",
    "    \n",
    "    return submission, cv_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " '.vscode',\n",
       " 'all_datasets.ipynb',\n",
       " 'all_submission.csv',\n",
       " 'app_test_all.csv',\n",
       " 'app_test_prv_apps.csv',\n",
       " 'app_train_all.csv',\n",
       " 'app_train_prv_apps.csv',\n",
       " 'buro.ipynb',\n",
       " 'data',\n",
       " 'defaultRisk.ipynb',\n",
       " 'home_credit.png',\n",
       " 'processed',\n",
       " 'proposal.pdf',\n",
       " 'README.md',\n",
       " 'submissions',\n",
       " 'test_bureau_raw.csv',\n",
       " 'train_bureau_raw.csv',\n",
       " 'utils']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('app_train_all.csv')\n",
    "test = pd.read_csv('app_test_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.827369\tvalid's auc: 0.784765\n",
      "[400]\ttrain's auc: 0.86228\tvalid's auc: 0.78625\n",
      "Early stopping, best iteration is:\n",
      "[319]\ttrain's auc: 0.849447\tvalid's auc: 0.786609\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.82745\tvalid's auc: 0.788103\n",
      "[400]\ttrain's auc: 0.862458\tvalid's auc: 0.789872\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttrain's auc: 0.868691\tvalid's auc: 0.790078\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.827583\tvalid's auc: 0.783203\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttrain's auc: 0.833857\tvalid's auc: 0.784189\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.827626\tvalid's auc: 0.78719\n",
      "[400]\ttrain's auc: 0.8621\tvalid's auc: 0.789449\n",
      "[600]\ttrain's auc: 0.888191\tvalid's auc: 0.788908\n",
      "Early stopping, best iteration is:\n",
      "[509]\ttrain's auc: 0.877108\tvalid's auc: 0.789758\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.827252\tvalid's auc: 0.784813\n",
      "[400]\ttrain's auc: 0.862013\tvalid's auc: 0.786845\n",
      "Early stopping, best iteration is:\n",
      "[373]\ttrain's auc: 0.8581\tvalid's auc: 0.787077\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.827815\tvalid's auc: 0.779591\n",
      "[400]\ttrain's auc: 0.861577\tvalid's auc: 0.780615\n",
      "Early stopping, best iteration is:\n",
      "[320]\ttrain's auc: 0.849498\tvalid's auc: 0.780941\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.827415\tvalid's auc: 0.784019\n",
      "[400]\ttrain's auc: 0.861655\tvalid's auc: 0.784756\n",
      "Early stopping, best iteration is:\n",
      "[326]\ttrain's auc: 0.850499\tvalid's auc: 0.785211\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.827642\tvalid's auc: 0.780828\n",
      "[400]\ttrain's auc: 0.862054\tvalid's auc: 0.781624\n",
      "Early stopping, best iteration is:\n",
      "[309]\ttrain's auc: 0.847875\tvalid's auc: 0.781874\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.828054\tvalid's auc: 0.781242\n",
      "Early stopping, best iteration is:\n",
      "[261]\ttrain's auc: 0.839914\tvalid's auc: 0.781958\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.827505\tvalid's auc: 0.786533\n",
      "Early stopping, best iteration is:\n",
      "[264]\ttrain's auc: 0.839939\tvalid's auc: 0.787534\n",
      "Overall CV Score: 0.79\n"
     ]
    }
   ],
   "source": [
    "submissions, cv_score = train_predict_lgbm(train,test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.to_csv('cv_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
