{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import Imputer\n",
    "import lightgbm as lgbm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from utils import ftextraction\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "gc.enable()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded in: 1.10 minutes\n"
     ]
    }
   ],
   "source": [
    "#load datasets\n",
    "start = time.time()\n",
    "app_train = pd.read_csv('data/application_train.csv')\n",
    "app_test = pd.read_csv('data/application_test.csv')\n",
    "buro = pd.read_csv('data/bureau.csv')\n",
    "bb = pd.read_csv('data/bureau_balance.csv')\n",
    "ccb = pd.read_csv('data/credit_card_balance.csv')\n",
    "ipay = pd.read_csv('data/installments_payments.csv')\n",
    "pos = pd.read_csv('data/POS_CASH_balance.csv')\n",
    "pa = pd.read_csv('data/previous_application.csv')\n",
    "end = time.time()\n",
    "print('Datasets loaded in: {:.2f} minutes'.format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process datasets\n",
    "start = time.time()\n",
    "fe = ftextraction.Extractor()\n",
    "data = fe.process_datasets(app_train,app_test,buro,bb,pa,ipay,ccb,pos)\n",
    "end = time.time()\n",
    "print('Datasets processed in: {:.2f} minutes'.format((end-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    \"\"\"Credit Risk Default Prediction Model\n",
    "    \n",
    "       Parameters:\n",
    "       -----------\n",
    "       data(pandas dataframe): training and testing dataset\n",
    "       \n",
    "       Returns:\n",
    "       -------\n",
    "       submission(pandas dataframe): test set predictions\n",
    "       scores(pandas dataframe): model training and validation scores\n",
    "       feature_importances(pandas dataframe): feature importance of the model\n",
    "       fprs(dictionary): false positive rates across folds\n",
    "       tprs(dictionary): true positive rates acrros folds\n",
    "       aucs(list): roc auc score across folds \n",
    "       \n",
    "    \"\"\"   \n",
    "    #preprocessing data    \n",
    "    train = data.loc[data['TARGET'].notnull(),:].copy()\n",
    "    test = data.loc[data['TARGET'].isnull(),:].copy()\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "    # save test IDs for final submission dataframe\n",
    "    test_IDs = test['SK_ID_CURR']\n",
    "    # save target labels\n",
    "    labels = train['TARGET']\n",
    "    # drop ID columns\n",
    "    train = train.drop(columns=['SK_ID_CURR','TARGET'])\n",
    "    test = test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "    #feature selection from previous runs\n",
    "    fi = pd.read_csv('fi_lgbm_V0_fe.csv')\n",
    "    exclude = list(fi.loc[fi['importance']==0,'features'])\n",
    "    \n",
    "    # drop features with no importance\n",
    "    train.drop(columns=exclude,inplace=True)\n",
    "    test.drop(columns=exclude,inplace=True)\n",
    "\n",
    "    # aligining dataframes\n",
    "    train,test = train.align(test,join='inner',axis=1)\n",
    "\n",
    "    # for storing feature importances\n",
    "    features = list(train.columns)\n",
    "    ft_importances = np.zeros(len(features))\n",
    "\n",
    "    # converting to numpy array for lgbm consumptions\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "\n",
    "    #DATA STRUCTURES TO STORE PREDICTIONS AND METRICS\n",
    "\n",
    "    #store cv predictions\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    #store predictions on test dataset\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    #store predictions on train dataset\n",
    "    train_preds = np.zeros(train.shape[0])\n",
    "    #store scores\n",
    "    scores = {}\n",
    "\n",
    "    #SPLITTING AND TRAINING \n",
    "    kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=40)\n",
    "    fold = 1\n",
    "    start = time.time()\n",
    "    fprs = {}\n",
    "    tprs = {}\n",
    "    aucs = []\n",
    "    print('Training started')\n",
    "    for train_i,valid_i in kfold.split(train,labels):\n",
    "        xtrain,ytrain = train[train_i],labels[train_i]\n",
    "        xvalid,yvalid = train[valid_i],labels[valid_i]\n",
    "    \n",
    "        # creating the classifier \n",
    "        clf = lgbm.LGBMClassifier(boosting_type='gbdt',num_leaves=40,\n",
    "                                 learning_rate=0.02,reg_alpha=1,\n",
    "                                 min_child_samples=45,reg_lambda=0.142857,\n",
    "                                 colsample_bytree=0.5,subsample=0.915152,\n",
    "                                 is_unbalance=True,\n",
    "                                 n_estimators=10000,random_state=50)\n",
    "\n",
    "        # fitting on the training set\n",
    "        clf.fit(xtrain,ytrain,eval_set=[(xtrain, ytrain), (xvalid, yvalid)],eval_metric ='auc',\n",
    "                verbose= 100, early_stopping_rounds= 100,eval_names = ['train','valid'])\n",
    "\n",
    "        #best iteration\n",
    "        best_iter = clf.best_iteration_\n",
    "        \n",
    "        # storing out of fold predictions:\n",
    "        oof_predictions[valid_i] = clf.predict_proba(xvalid,num_iteration=best_iter)[:, 1]\n",
    "\n",
    "        # storing test set predictions:\n",
    "        test_preds += clf.predict_proba(test,num_iteration=best_iter)[:, 1] /kfold.n_splits\n",
    "\n",
    "        #stortin training set predictions\n",
    "        train_preds[train_i] = clf.predict_proba(xtrain,num_iteration=best_iter)[:, 1]\n",
    "\n",
    "        # storing feature importances            \n",
    "        ft_importances += clf.feature_importances_ /kfold.n_splits\n",
    "        \n",
    "        #false and true positive rates for plotting roc curve\n",
    "        fpr,tpr,threshold = roc_curve(yvalid,oof_predictions[valid_i])\n",
    "        fprs[f'fold_{fold}'] = fpr\n",
    "        tprs[f'fold_{fold}'] = tpr\n",
    "        rauc_scr = auc(fpr,tpr)\n",
    "        aucs.append(rauc_scr)\n",
    "        print('Fold %d done.'%fold)\n",
    "        fold += 1\n",
    "\n",
    "        # freeing up memory\n",
    "        del xtrain,ytrain,xvalid,yvalid,clf\n",
    "        gc.collect()\n",
    "        \n",
    "    end = time.time()    \n",
    "    print('Training done in {:.2f} minutes'.format((end-start)/60))    \n",
    "    #SCORES\n",
    "\n",
    "    feature_importances = pd.DataFrame({'features':features,'importance':ft_importances})\n",
    "    \n",
    "    training_score = roc_auc_score(labels,train_preds)\n",
    "    cv = roc_auc_score(labels,oof_predictions)\n",
    "    \n",
    "    fpr,tpr,threshold = roc_curve(labels,oof_predictions)\n",
    "    fprs['OCV'] = fpr\n",
    "    tprs['OCV'] = tpr\n",
    "    aucs.append(cv) \n",
    "    \n",
    "    scores['training score'] = [training_score]\n",
    "    scores['cv score'] = [cv]\n",
    "    scores = pd.DataFrame.from_dict(scores)\n",
    "    print('Overall CV Score: %.4f' %cv)\n",
    "    # submission dataframe:\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_IDs, 'TARGET': test_preds})\n",
    "\n",
    "    return submission, scores, feature_importances,fprs,tprs,aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission, scores, feature_importances,fprs,tprs,aucs = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
