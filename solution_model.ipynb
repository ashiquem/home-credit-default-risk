{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import ftextraction\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import Imputer\n",
    "import lightgbm as lgbm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from utils import plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "gc.enable()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "start = time.time()\n",
    "app_train = pd.read_csv('data/application_train.csv')\n",
    "app_test = pd.read_csv('data/application_test.csv')\n",
    "buro = pd.read_csv('data/bureau.csv')\n",
    "bb = pd.read_csv('data/bureau_balance.csv')\n",
    "ccb = pd.read_csv('data/credit_card_balance.csv')\n",
    "ipay = pd.read_csv('data/installments_payments.csv')\n",
    "pos = pd.read_csv('data/POS_CASH_balance.csv')\n",
    "pa = pd.read_csv('data/previous_application.csv')\n",
    "end = time.time()\n",
    "print('Datasets loaded in: {:.2f} minutes'.format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process datasets\n",
    "start = time.time()\n",
    "data = fe.process_datasets(app_train,app_test,buro,bb,pa,ipay,ccb,pos)\n",
    "end = time.time()\n",
    "print('Datasets processed in: {:.2f} minutes'.format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed/alldata_fe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection from previous runs\n",
    "fi = pd.read_csv('fi_lgbm_V0_fe.csv')\n",
    "no_imp=list(fi.loc[fi['importance']==0,'features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data,folds,iterations,exclude=[]):\n",
    "       \n",
    "    #preprocessing data    \n",
    "    train = data.loc[data['TARGET'].notnull(),:].copy()\n",
    "    test = data.loc[data['TARGET'].isnull(),:].copy()\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "    # save test IDs for final submission dataframe\n",
    "    test_IDs = test['SK_ID_CURR']\n",
    "    # save target labels\n",
    "    labels = train['TARGET']\n",
    "    # drop ID columns\n",
    "    train = train.drop(columns=['SK_ID_CURR','TARGET'])\n",
    "    test = test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "\n",
    "    # drop features with no importance\n",
    "    train.drop(columns=exclude,inplace=True)\n",
    "    test.drop(columns=exclude,inplace=True)\n",
    "\n",
    "    # aligining dataframes\n",
    "    train,test = train.align(test,join='inner',axis=1)\n",
    "\n",
    "    # for storing feature importances\n",
    "    features = list(train.columns)\n",
    "    ft_importances = np.zeros(len(features))\n",
    "\n",
    "    # converting to numpy array for lgbm consumptions\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "\n",
    "    #DATA STRUCTURES TO STORE PREDICTIONS AND METRICS\n",
    "\n",
    "    #store cv predictions\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    #store predictions on test dataset\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    #store predictions on train dataset\n",
    "    train_preds = np.zeros(train.shape[0])\n",
    "    #store scores\n",
    "    scores = {}\n",
    "\n",
    "    #SPLITTING AND TRAINING \n",
    "    kfold = StratifiedKFold(n_splits=folds,shuffle=True,random_state=40)\n",
    "    fold = 1\n",
    "    start = time.time()\n",
    "    fprs = {}\n",
    "    tprs = {}\n",
    "    aucs = []\n",
    "    models = []\n",
    "    print('Training started')\n",
    "    for train_i,valid_i in kfold.split(train,labels):\n",
    "        xtrain,ytrain = train[train_i],labels[train_i]\n",
    "        xvalid,yvalid = train[valid_i],labels[valid_i]\n",
    "    \n",
    "        # creating the classifier \n",
    "        clf = lgbm.LGBMClassifier(boosting_type='gbdt',num_leaves=40,\n",
    "                                 learning_rate=0.02,reg_alpha=1,\n",
    "                                 min_child_samples=45,reg_lambda=0.142857,\n",
    "                                 colsample_bytree=0.5,subsample=0.915152,\n",
    "                                 is_unbalance=True,\n",
    "                                 n_estimators=10000,random_state=50)\n",
    "\n",
    "        # fitting on the training set\n",
    "        clf.fit(xtrain,ytrain,eval_set=[(xtrain, ytrain), (xvalid, yvalid)],eval_metric ='auc',\n",
    "                verbose= 200, early_stopping_rounds= iterations,eval_names = ['train','valid'])\n",
    "\n",
    "        #best iteration\n",
    "        best_iter = clf.best_iteration_\n",
    "        \n",
    "        # storing out of fold predictions:\n",
    "        oof_predictions[valid_i] = clf.predict_proba(xvalid,num_iteration=best_iter)[:, 1]\n",
    "\n",
    "        # storing test set predictions:\n",
    "        test_preds += clf.predict_proba(test,num_iteration=best_iter)[:, 1] /kfold.n_splits\n",
    "\n",
    "        #stortin training set predictions\n",
    "        train_preds[train_i] = clf.predict_proba(xtrain,num_iteration=best_iter)[:, 1]\n",
    "\n",
    "        # storing feature importances            \n",
    "        ft_importances += clf.feature_importances_ /kfold.n_splits\n",
    "        \n",
    "        #false and true positive rates for plotting roc curve\n",
    "        fpr,tpr,threshold = roc_curve(yvalid,oof_predictions[valid_i])\n",
    "        fprs[f'fold_{fold}'] = fpr\n",
    "        tprs[f'fold_{fold}'] = tpr\n",
    "        rauc_scr = auc(fpr,tpr)\n",
    "        aucs.append(rauc_scr)\n",
    "        print('Fold %d done.'%fold)\n",
    "        fold += 1\n",
    "        #store model\n",
    "        models.append(clf)\n",
    "        # freeing up memory\n",
    "        del xtrain,ytrain,xvalid,yvalid,clf\n",
    "        gc.collect()\n",
    "        \n",
    "    end = time.time()    \n",
    "    print('Training done in {:.2f} minutes'.format((end-start)/60))    \n",
    "    #SCORES\n",
    "\n",
    "    feature_importances = pd.DataFrame({'features':features,'importance':ft_importances})\n",
    "    \n",
    "    training_score = roc_auc_score(labels,train_preds)\n",
    "    cv = roc_auc_score(labels,oof_predictions)\n",
    "    \n",
    "    fpr,tpr,threshold = roc_curve(labels,oof_predictions)\n",
    "    fprs['OCV'] = fpr\n",
    "    tprs['OCV'] = tpr\n",
    "    aucs.append(cv) \n",
    "    \n",
    "    scores['training score'] = [training_score]\n",
    "    scores['cv score'] = [cv]\n",
    "    scores = pd.DataFrame.from_dict(scores)\n",
    "    print('Overall CV Score: %.4f' %cv)\n",
    "    # submission dataframe:\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_IDs, 'TARGET': test_preds})\n",
    "\n",
    "    return models,submission, scores, feature_importances,fprs,tprs,aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.808119\tvalid's auc: 0.77221\n",
      "[400]\ttrain's auc: 0.833554\tvalid's auc: 0.781392\n",
      "[600]\ttrain's auc: 0.852561\tvalid's auc: 0.784194\n",
      "Early stopping, best iteration is:\n",
      "[690]\ttrain's auc: 0.859911\tvalid's auc: 0.784741\n",
      "Fold 1 done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.807494\tvalid's auc: 0.782062\n",
      "[400]\ttrain's auc: 0.83314\tvalid's auc: 0.790447\n",
      "[600]\ttrain's auc: 0.852165\tvalid's auc: 0.792066\n",
      "Early stopping, best iteration is:\n",
      "[690]\ttrain's auc: 0.859562\tvalid's auc: 0.79251\n",
      "Fold 2 done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.807857\tvalid's auc: 0.778914\n",
      "[400]\ttrain's auc: 0.833242\tvalid's auc: 0.786983\n",
      "[600]\ttrain's auc: 0.852345\tvalid's auc: 0.788947\n",
      "[800]\ttrain's auc: 0.868014\tvalid's auc: 0.78963\n",
      "Early stopping, best iteration is:\n",
      "[806]\ttrain's auc: 0.868421\tvalid's auc: 0.78966\n",
      "Fold 3 done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.808041\tvalid's auc: 0.77435\n",
      "[400]\ttrain's auc: 0.833681\tvalid's auc: 0.78309\n",
      "[600]\ttrain's auc: 0.852632\tvalid's auc: 0.785131\n",
      "Early stopping, best iteration is:\n",
      "[698]\ttrain's auc: 0.860573\tvalid's auc: 0.78567\n",
      "Fold 4 done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.807713\tvalid's auc: 0.776317\n",
      "[400]\ttrain's auc: 0.833228\tvalid's auc: 0.786287\n",
      "[600]\ttrain's auc: 0.852222\tvalid's auc: 0.789518\n",
      "[800]\ttrain's auc: 0.867856\tvalid's auc: 0.790362\n",
      "Early stopping, best iteration is:\n",
      "[880]\ttrain's auc: 0.873744\tvalid's auc: 0.790704\n",
      "Fold 5 done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.807319\tvalid's auc: 0.78291\n",
      "[400]\ttrain's auc: 0.832672\tvalid's auc: 0.791952\n",
      "[600]\ttrain's auc: 0.851434\tvalid's auc: 0.794409\n",
      "[800]\ttrain's auc: 0.866962\tvalid's auc: 0.795284\n",
      "[1000]\ttrain's auc: 0.880622\tvalid's auc: 0.795648\n",
      "[1200]\ttrain's auc: 0.892885\tvalid's auc: 0.795993\n",
      "Early stopping, best iteration is:\n",
      "[1229]\ttrain's auc: 0.894577\tvalid's auc: 0.796071\n",
      "Fold 6 done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.808159\tvalid's auc: 0.774113\n",
      "[400]\ttrain's auc: 0.833553\tvalid's auc: 0.782692\n",
      "[600]\ttrain's auc: 0.852524\tvalid's auc: 0.784895\n",
      "[800]\ttrain's auc: 0.868291\tvalid's auc: 0.785503\n",
      "Early stopping, best iteration is:\n",
      "[753]\ttrain's auc: 0.864818\tvalid's auc: 0.785583\n",
      "Fold 7 done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.808027\tvalid's auc: 0.772795\n",
      "[400]\ttrain's auc: 0.833553\tvalid's auc: 0.781515\n",
      "[600]\ttrain's auc: 0.85229\tvalid's auc: 0.783828\n",
      "[800]\ttrain's auc: 0.867717\tvalid's auc: 0.7841\n",
      "Early stopping, best iteration is:\n",
      "[853]\ttrain's auc: 0.871456\tvalid's auc: 0.78425\n",
      "Fold 8 done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.807449\tvalid's auc: 0.783397\n",
      "[400]\ttrain's auc: 0.833013\tvalid's auc: 0.791547\n",
      "[600]\ttrain's auc: 0.852054\tvalid's auc: 0.793473\n",
      "[800]\ttrain's auc: 0.867829\tvalid's auc: 0.794075\n",
      "[1000]\ttrain's auc: 0.881583\tvalid's auc: 0.794251\n",
      "Early stopping, best iteration is:\n",
      "[1092]\ttrain's auc: 0.887481\tvalid's auc: 0.794696\n",
      "Fold 9 done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's auc: 0.807685\tvalid's auc: 0.778993\n",
      "[400]\ttrain's auc: 0.833222\tvalid's auc: 0.78863\n",
      "[600]\ttrain's auc: 0.852121\tvalid's auc: 0.791422\n",
      "[800]\ttrain's auc: 0.867771\tvalid's auc: 0.791947\n",
      "Early stopping, best iteration is:\n",
      "[884]\ttrain's auc: 0.873822\tvalid's auc: 0.792071\n",
      "Fold 10 done.\n",
      "Training done in 19.67 minutes\n",
      "Overall CV Score: 0.7895\n"
     ]
    }
   ],
   "source": [
    "models,submission, scores, feature_importances,fprs,tprs,aucs = model(data,10,100,exclude=no_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('fsubmission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
